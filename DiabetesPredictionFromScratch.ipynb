{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJr8HDT6UxC4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCxJOcuGfn9L"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/ML Datasets/diabetes-dataset.csv\")\n",
        "dataset = dataset.sample(frac=1)\n",
        "\n",
        "X = dataset.drop(\"Outcome\", axis=1)\n",
        "y = dataset[\"Outcome\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BB7HnijVQBE"
      },
      "source": [
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n",
        "X_train = np.array(train_X)\n",
        "X_test = np.array(test_X)\n",
        "y_train = np.array(train_y)\n",
        "y_test = np.array(test_y)\n",
        "\n",
        "X_train = X_train.T\n",
        "X_test = X_test.T\n",
        "y_train = y_train.reshape(1, y_train.shape[0])\n",
        "y_test = y_test.reshape(1, y_test.shape[0])\n",
        "\n",
        "print(\"X_train shape: \" + str(X_train.shape))\n",
        "print(\"y_train shape: \" + str(y_train.shape))\n",
        "print(\"X_test shape: \" + str(X_test.shape))\n",
        "print(\"y_test shape: \" + str(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxEjqY-BrnUG"
      },
      "source": [
        "def structure(X, Y):\n",
        "  input_size = X.shape[0]\n",
        "  hidden_size = 8\n",
        "  output_size = Y.shape[0]\n",
        "\n",
        "  return input_size, hidden_size, output_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22Im0qITvmOX"
      },
      "source": [
        "def initialize(input_size, hidden_size, output_size):\n",
        "  W1 = np.random.randn(hidden_size, input_size) * 0.001\n",
        "  b1 = np.zeros(shape=(hidden_size, 1))\n",
        "  W2 = np.random.randn(output_size, hidden_size)\n",
        "  b2 = np.zeros(shape=(output_size, 1))\n",
        "\n",
        "  params = {\"W1\": W1,\n",
        "            \"W2\": W2,\n",
        "            \"b1\": b1,\n",
        "            \"b2\": b2}\n",
        "\n",
        "  return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByO5F3p-x7Q1"
      },
      "source": [
        "def sigmoid(x):\n",
        "  y = 1/(1+np.exp(-x))\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5a9x58T08Ci"
      },
      "source": [
        "def forward_prop(X, params):\n",
        "  W1 = params[\"W1\"]\n",
        "  b1 = params[\"b1\"]\n",
        "  W2 = params[\"W2\"]\n",
        "  b2 = params[\"b2\"]\n",
        "\n",
        "  Z1 = np.dot(W1, X) + b1\n",
        "  A1 = np.tanh(Z1)\n",
        "  Z2 = np.dot(W2, A1) + b2\n",
        "  A2 = sigmoid(Z2) + b2\n",
        "\n",
        "  vars = {\"Z1\": Z1,\n",
        "          \"A1\": A1,\n",
        "          \"Z2\": Z2,\n",
        "          \"A2\": A2}\n",
        "  #return output and dict containing internal variables\n",
        "  return A2, vars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tHtNN2A5zpK"
      },
      "source": [
        "def cost(A2, Y):\n",
        "  m = Y.shape[1]\n",
        "  cost = (-1/m) * np.sum(Y * np.log(A2) + (1-Y) * (np.log(1-A2)))\n",
        "\n",
        "  cost = np.squeeze(cost)\n",
        "\n",
        "  return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qbtaj9Y8OEi"
      },
      "source": [
        "def backprop(X, Y, vars, params):\n",
        "  m = Y.shape[1]\n",
        "\n",
        "  Z1 = vars[\"Z1\"]\n",
        "  A1 = vars[\"A1\"]\n",
        "  Z2 = vars[\"Z2\"]\n",
        "  A2 = vars[\"A2\"]\n",
        "\n",
        "  W1 = params[\"W1\"]\n",
        "  b1 = params[\"b1\"]\n",
        "  W2 = params[\"W2\"]\n",
        "  b2 = params[\"b2\"]\n",
        "\n",
        "  dZ2 = A2 - Y\n",
        "  dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
        "  db2 = (1/m) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "  dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))\n",
        "  dW1 = (1/m) * np.dot(dZ1, X.T)\n",
        "  db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "  grads = {\"dZ2\": dZ2,\n",
        "           \"dW2\": dW2,\n",
        "           \"db2\": db2,\n",
        "           \"dZ1\": dZ1,\n",
        "           \"dW1\": dW1,\n",
        "           \"db1\": db1}\n",
        "  return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fBEqQrNfBnr"
      },
      "source": [
        "def update(params, grads, learning_rate):\n",
        "\n",
        "  W1 = params[\"W1\"]\n",
        "  b1 = params[\"b1\"]\n",
        "  W2 = params[\"W2\"]\n",
        "  b2 = params[\"b2\"]\n",
        "\n",
        "  dZ2 = grads[\"dZ2\"]\n",
        "  dW2 = grads[\"dW2\"]\n",
        "  db2 = grads[\"db2\"]\n",
        "  dZ1 = grads[\"dZ1\"]\n",
        "  dW1 = grads[\"dW1\"]\n",
        "  db1 = grads[\"db1\"]\n",
        "\n",
        "  W1 = W1 - dW1 * learning_rate\n",
        "  b1 = b1 - db1 * learning_rate\n",
        "  W2 = W2 - dW2 * learning_rate\n",
        "  b2 = b2 - db2 * learning_rate\n",
        "\n",
        "  params = {\"W1\": W1,\n",
        "            \"W2\": W2,\n",
        "            \"b1\": b1,\n",
        "            \"b2\": b2}\n",
        "\n",
        "  return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzKNOPRBjDCs"
      },
      "source": [
        "def model(X, Y, iterations, learning_rate):\n",
        "\n",
        "  params = initialize(structure(X,Y)[0], structure(X,Y)[1], structure(X,Y)[2])\n",
        "\n",
        "  W1 = params[\"W1\"]\n",
        "  b1 = params[\"b1\"]\n",
        "  W2 = params[\"W2\"]\n",
        "  b2 = params[\"b2\"]\n",
        "\n",
        "  for i in range(iterations):\n",
        "    A2, vars = forward_prop(X, params)\n",
        "    cost_func = cost(A2, Y)\n",
        "    grads = backprop(X, Y, vars, params)\n",
        "    params = update(params, grads, learning_rate)\n",
        "    if i % 500 == 0:\n",
        "      print(\"Cost after iteration\", i, \": \", cost_func)\n",
        "\n",
        "  return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ8K7GVNmzKP"
      },
      "source": [
        "def predict(X, params):\n",
        "  A2, vars = forward_prop(X, params)\n",
        "  prediction = A2.round()\n",
        "\n",
        "  return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkcwGlOsoc8k"
      },
      "source": [
        "def test(X1, y1, X2, y2, iterations, learning_rate):\n",
        "  params = model(X1, y1, iterations, learning_rate)\n",
        "  predictions = predict(X1, params)\n",
        "\n",
        "  print(\"Training Accuracy: %d\" % float((np.dot(y1, predictions.T) + np.dot(1 - y1, 1 - predictions.T)) / float(y1.size) * 100) + '%')\n",
        "\n",
        "  predictions = predict(X2, params)\n",
        "\n",
        "  print(\"Testing Accuracy: %d\" % float((np.dot(y2, predictions.T) + np.dot(1 - y2, 1 - predictions.T)) / float(y2.size) * 100) + '%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za7gd2PJuyY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466e389f-0efd-47c2-d00f-1f771edc64dd"
      },
      "source": [
        "test(X_train, y_train, X_test, y_test, 10000, 0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0 :  0.6946266177152596\n",
            "Cost after iteration 500 :  0.5933524372063527\n",
            "Cost after iteration 1000 :  0.6019368556679006\n",
            "Cost after iteration 1500 :  0.5738257620057725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in log\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 2000 :  0.5574435979999907\n",
            "Cost after iteration 2500 :  nan\n",
            "Cost after iteration 3000 :  nan\n",
            "Cost after iteration 3500 :  nan\n",
            "Cost after iteration 4000 :  nan\n",
            "Cost after iteration 4500 :  nan\n",
            "Cost after iteration 5000 :  nan\n",
            "Cost after iteration 5500 :  0.5502893210101126\n",
            "Cost after iteration 6000 :  0.549967017742027\n",
            "Cost after iteration 6500 :  0.5539345004336369\n",
            "Cost after iteration 7000 :  0.5476526337783778\n",
            "Cost after iteration 7500 :  0.5446212623776147\n",
            "Cost after iteration 8000 :  0.539327548615442\n",
            "Cost after iteration 8500 :  0.5369691770588151\n",
            "Cost after iteration 9000 :  0.5354872005911593\n",
            "Cost after iteration 9500 :  0.5343786218283527\n",
            "Training Accuracy: 74%\n",
            "Testing Accuracy: 71%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}